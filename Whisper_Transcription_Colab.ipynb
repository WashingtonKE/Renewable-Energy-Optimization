{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WashingtonKE/Renewable-Energy-Optimization/blob/main/Whisper_Transcription_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RahQuKNI_Afx"
      },
      "source": [
        "# ðŸŽ§ Whisper Transcription â€“ Google Colab Notebook\n",
        "\n",
        "This notebook lets you transcribe audio (e.g., `.aac`, `.mp3`, `.wav`, `.m4a`) using [OpenAI Whisper](https://github.com/openai/whisper) in Google Colab.\n",
        "\n",
        "## How to use\n",
        "1. **Run each cell in order** (Shift+Enter).\n",
        "2. Upload your audio file when prompted.\n",
        "3. The transcript will be printed and saved as `transcript.txt` (and optionally `transcript.srt`).\n",
        "\n",
        "**Tip:** Change `MODEL_SIZE` to `small`, `medium`, or `large` for higher accuracy (needs more GPU memory/time).\n"
      ],
      "id": "RahQuKNI_Afx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbS6K4Zm_Af3"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ðŸ› ï¸ Step 1: Install Whisper and FFmpeg\n",
        "!pip -q install openai-whisper\n",
        "!sudo apt -yq update && !sudo apt -yq install ffmpeg\n",
        "print(\"Installation complete.\")"
      ],
      "id": "TbS6K4Zm_Af3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h31GBC26_Af6"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ðŸŽšï¸ Step 2: (Optional) Choose model size and language\n",
        "MODEL_SIZE = \"base\"  # options: tiny, base, small, medium, large\n",
        "FORCE_LANGUAGE = None  # e.g., \"en\" for English, \"sw\" for Swahili; set to None to auto-detect\n",
        "print(f\"Model size set to: {MODEL_SIZE}\")\n",
        "print(f\"Force language: {FORCE_LANGUAGE}\")"
      ],
      "id": "h31GBC26_Af6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6mNeE0C_Af6"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ðŸ“¤ Step 3: Upload your audio file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "assert uploaded, \"No file uploaded. Please run this cell again and select an audio file.\"\n",
        "FILENAME = list(uploaded.keys())[0]\n",
        "print(\"Uploaded:\", FILENAME)"
      ],
      "id": "J6mNeE0C_Af6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnZGztuh_Af7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ðŸ¤– Step 4: Transcribe with Whisper\n",
        "import whisper, torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = whisper.load_model(MODEL_SIZE, device=device)\n",
        "kwargs = {}\n",
        "if FORCE_LANGUAGE:\n",
        "    kwargs[\"language\"] = FORCE_LANGUAGE\n",
        "\n",
        "result = model.transcribe(FILENAME, **kwargs)\n",
        "text = result.get(\"text\", \"\").strip()\n",
        "print(\"\\n--- TRANSCRIPTION ---\\n\")\n",
        "print(text if text else \"(No speech recognized or empty transcript)\")"
      ],
      "id": "QnZGztuh_Af7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IljYlYc_Af8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ðŸ’¾ Step 5: Save transcript and subtitles, then download\n",
        "from google.colab import files\n",
        "\n",
        "# Save plain text transcript\n",
        "txt_name = \"transcript.txt\"\n",
        "with open(txt_name, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(result.get(\"text\", \"\").strip())\n",
        "print(\"Saved:\", txt_name)\n",
        "\n",
        "# Create simple SRT subtitles from segments\n",
        "def to_srt(segments, path):\n",
        "    def fmt(t):\n",
        "        h = int(t // 3600)\n",
        "        m = int((t % 3600) // 60)\n",
        "        s = int(t % 60)\n",
        "        ms = int((t - int(t)) * 1000)\n",
        "        return f\"{h:02d}:{m:02d}:{s:02d},{ms:03d}\"\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as srt:\n",
        "        for i, seg in enumerate(segments, start=1):\n",
        "            start = fmt(seg.get(\"start\", 0.0))\n",
        "            end = fmt(seg.get(\"end\", 0.0))\n",
        "            text = seg.get(\"text\", \"\").strip()\n",
        "            srt.write(f\"{i}\\n{start} --> {end}\\n{text}\\n\\n\")\n",
        "\n",
        "srt_name = \"transcript.srt\"\n",
        "to_srt(result.get(\"segments\", []), srt_name)\n",
        "print(\"Saved:\", srt_name)\n",
        "\n",
        "# Download files\n",
        "files.download(txt_name)\n",
        "files.download(srt_name)"
      ],
      "id": "7IljYlYc_Af8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}